{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15d91df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 1,\n",
       " 'message': 'The sea floor is sinking under the weight of climate change https://t.co/R9Uhnjfg7G',\n",
       " 'tweetid': 954625951685578752}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from CSV and prepare splits\n",
    "from datasets import load_dataset\n",
    "\n",
    "csv_path = r\"c:\\Users\\codes\\Documents\\Programming\\Summarized-Sentiment-Analyzer\\twitter_sentiment_data.csv\"\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": csv_path}, split=\"train\")\n",
    "\n",
    "# If your CSV has columns like 'text' and 'label' adjust here\n",
    "text_column = \"text\"\n",
    "label_column = \"label\"\n",
    "\n",
    "# Create validation split (10%)\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds = dataset[\"test\"]\n",
    "\n",
    "# Inspect a sample\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63be568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\codes\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\codes\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\codes\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\codes\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\codes\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install training dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c9095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install required packages (uncomment if needed)\n",
    "## Note: Running installs from the notebook may require internet access.\n",
    "## On Windows cmd, you can also install via terminal:\n",
    "## pip install --upgrade pip\n",
    "## pip install transformers torch sentencepiece\n",
    "\n",
    "# If you prefer inline install, uncomment the following:\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -U pip\n",
    "# !{sys.executable} -m pip install transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c51ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix notebook progress bars and optional HF Xet support\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade ipywidgets jupyter jupyterlab notebook\n",
    "# Optional: speed up Hugging Face downloads\n",
    "# !{sys.executable} -m pip install \"huggingface_hub[hf_xet]\"\n",
    "# Optional: silence symlink warning without enabling Developer Mode\n",
    "# import os\n",
    "# os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edc03e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)), '(Request ID: 8cc9747e-4fd6-47f6-aced-6d9d8de8a0bf)')' thrown while requesting HEAD https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RoBERTa sentiment pipeline using CardiffNLP model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Build a TextClassificationPipeline\n",
    "sentiment_pipeline = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "labels = model.config.id2label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d88f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this product! -> positive (0.985)\n",
      "This is the worst experience ever. -> negative (0.945)\n",
      "It's okay, nothing special. -> neutral (0.599)\n",
      "I hate you so much! -> negative (0.935)\n",
      "I adore you so much! -> positive (0.984)\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "texts = [\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst experience ever.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"I hate you so much!\",\n",
    "    \"I adore you so much!\"\n",
    "]\n",
    "\n",
    "results = sentiment_pipeline(texts, top_k=1)\n",
    "for text, res in zip(texts, results):\n",
    "    print(f\"{text} -> {res[0]['label']} ({res[0]['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9de6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 1: Data Loading & Preparation\n",
    "\n",
    "Load the labeled dataset with all required features: text, sentiment_label, timestamp, platform, and geolocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad0cd6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_temporal_10000.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load your pre-processed and labeled data\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Using 10K sample for faster training (~2-3 hours instead of 12)\u001b[39;00m\n\u001b[32m      7\u001b[39m csv_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain_temporal_10000.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Print actual columns to diagnose issues\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'train_temporal_10000.csv'"
     ]
    }
   ],
   "source": [
    "# Load labeled dataset with all features\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load your pre-processed and labeled data\n",
    "# Using 10K sample for faster training (~2-3 hours instead of 12)\n",
    "csv_path = r\"10k_sample.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Print actual columns to diagnose issues\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Auto-detect sentiment column name (flexible column naming)\n",
    "sentiment_col = None\n",
    "for possible_name in ['sentiment_label', 'sentiment', 'label', 'Sentiment', 'target']:\n",
    "    if possible_name in df.columns:\n",
    "        sentiment_col = possible_name\n",
    "        break\n",
    "\n",
    "if sentiment_col is None:\n",
    "    raise ValueError(f\"Could not find sentiment column. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nUsing '{sentiment_col}' as sentiment column\")\n",
    "\n",
    "# Auto-detect text column name\n",
    "text_col = None\n",
    "for possible_name in ['text', 'message', 'tweet', 'content', 'Message']:\n",
    "    if possible_name in df.columns:\n",
    "        text_col = possible_name\n",
    "        break\n",
    "\n",
    "if text_col is None:\n",
    "    raise ValueError(f\"Could not find text column. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(f\"Using '{text_col}' as text column\")\n",
    "\n",
    "# Standardize column names\n",
    "if sentiment_col != 'sentiment_label':\n",
    "    df['sentiment_label'] = df[sentiment_col]\n",
    "\n",
    "if text_col != 'text':\n",
    "    df['text'] = df[text_col]\n",
    "\n",
    "# Check label distribution BEFORE conversion\n",
    "print(f\"\\nOriginal Sentiment Distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "\n",
    "# Convert numeric sentiments to strings if needed\n",
    "# Common mappings: -1=Negative, 0=Neutral, 1=Positive, 2=Positive\n",
    "if df['sentiment_label'].dtype in ['int64', 'float64']:\n",
    "    print(\"\\nDetected numeric sentiments. Converting to strings...\")\n",
    "    numeric_to_string = {\n",
    "        -1: 'Negative',\n",
    "        0: 'Neutral',\n",
    "        1: 'Positive',\n",
    "        2: 'Positive'  # Sometimes datasets use 2 for positive\n",
    "    }\n",
    "    df['sentiment_label'] = df['sentiment_label'].map(numeric_to_string)\n",
    "    \n",
    "    print(f\"\\nAfter conversion:\")\n",
    "    print(df['sentiment_label'].value_counts())\n",
    "\n",
    "# Convert timestamps to datetime if timestamp column exists\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    print(f\"\\nDate Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "else:\n",
    "    print(\"\\nWarning: No 'timestamp' column found. Creating dummy timestamps.\")\n",
    "    df['timestamp'] = pd.date_range(start='2024-01-01', periods=len(df), freq='H')\n",
    "\n",
    "# Ensure other columns exist or create defaults\n",
    "if 'platform' not in df.columns:\n",
    "    print(\"Warning: No 'platform' column found. Creating default.\")\n",
    "    df['platform'] = 'Twitter'\n",
    "\n",
    "if 'geolocation' not in df.columns:\n",
    "    print(\"Warning: No 'geolocation' column found. Creating default.\")\n",
    "    df['geolocation'] = 'Unknown'\n",
    "\n",
    "print(f\"\\n✓ Data loading complete. Ready for label encoding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0074a06",
   "metadata": {},
   "source": [
    "## Phase 2: Label Encoding & Dataset Preparation\n",
    "\n",
    "Map sentiment labels to numeric IDs and prepare train/validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c81a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing labels after mapping: 0\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0     3990\n",
      "1     7715\n",
      "2    32238\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Split sizes:\n",
      "Train: 30760\n",
      "Validation: 6591\n",
      "Test: 6592\n",
      "\n",
      "✓ Datasets created successfully\n",
      "\n",
      "Split sizes:\n",
      "Train: 30760\n",
      "Validation: 6591\n",
      "Test: 6592\n",
      "\n",
      "✓ Datasets created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create label mapping: Positive=2, Neutral=1, Negative=0\n",
    "label_map = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "id2label = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Encode labels (sentiment_label column now exists from previous cell)\n",
    "df['label'] = df['sentiment_label'].map(label_map)\n",
    "\n",
    "# Verify no missing labels after mapping\n",
    "missing_count = df['label'].isna().sum()\n",
    "print(f\"Missing labels after mapping: {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(f\"\\nWarning: Found {missing_count} unmapped labels. These will be removed.\")\n",
    "    print(f\"Unmapped values: {df[df['label'].isna()]['sentiment_label'].unique()}\")\n",
    "    df = df.dropna(subset=['label'])\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts().sort_index())\n",
    "\n",
    "# Create train/validation/test splits (70/15/15)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"Train: {len(train_df)}\")\n",
    "print(f\"Validation: {len(val_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']].reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df[['text', 'label']].reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label', 'timestamp', 'platform', 'geolocation']].reset_index(drop=True))\n",
    "\n",
    "print(f\"\\n✓ Datasets created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f98b5e",
   "metadata": {},
   "source": [
    "## Phase 3: Model Fine-Tuning Setup\n",
    "\n",
    "Configure RoBERTa tokenizer and prepare datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f35d218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc979aae36349559b5dbaffc1c6209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ba003dac134700971be869458473b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c9b9e977ea4a9fae30191013945383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: CPU\n",
      "Tokenized train samples: 30760\n"
     ]
    }
   ],
   "source": [
    "# Initialize RoBERTa tokenizer and tokenize datasets\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=512, padding=False)\n",
    "\n",
    "# Tokenize all datasets\n",
    "train_tokenized = train_dataset.map(preprocess_function, batched=True)\n",
    "val_tokenized = val_dataset.map(preprocess_function, batched=True)\n",
    "test_tokenized = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Tokenized train samples: {len(train_tokenized)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196385e",
   "metadata": {},
   "source": [
    "## Phase 4: Model Fine-Tuning & Training\n",
    "\n",
    "Configure model architecture, training arguments, and execute fine-tuning with comprehensive metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce9121ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Accelerate installed. If you still see errors, restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "# Install training dependencies (accelerate required for Trainer)\n",
    "# IMPORTANT: After running this cell, you may need to restart the kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q accelerate>=0.26.0\n",
    "\n",
    "# Force reload transformers to pick up newly installed accelerate\n",
    "import importlib\n",
    "import transformers\n",
    "importlib.reload(transformers)\n",
    "\n",
    "print(\"✓ Accelerate installed. If you still see errors, restart the kernel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de25d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fine-tuning...\n",
      "Training samples: 30760\n",
      "Validation samples: 6591\n",
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codes\\AppData\\Local\\Temp\\ipykernel_18128\\1929521756.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Configure RoBERTa model and training pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# Initialize model with label mappings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label_map\n",
    ")\n",
    "\n",
    "# Define comprehensive evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1_macro\": f1_score(labels, predictions, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, predictions, average=\"weighted\"),\n",
    "        \"f1_per_class\": f1_score(labels, predictions, average=None).tolist()\n",
    "    }\n",
    "\n",
    "# Training configuration optimized for sentiment analysis\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/roberta-environmental-sentiment\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision if GPU available\n",
    "    report_to=\"none\",  # Disable wandb/tensorboard for now\n",
    ")\n",
    "\n",
    "# Initialize Trainer with early stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "print(\"Starting model fine-tuning...\")\n",
    "print(f\"Training samples: {len(train_tokenized)}\")\n",
    "print(f\"Validation samples: {len(val_tokenized)}\")\n",
    "print(f\"Device: {training_args.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "560e87b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2784' max='9615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2784/9615 3:27:02 < 8:28:21, 0.22 it/s, Epoch 1.45/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>F1 Per Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.438600</td>\n",
       "      <td>0.421441</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.716339</td>\n",
       "      <td>0.830377</td>\n",
       "      <td>[0.6596558317399618, 0.5772655840754322, 0.9120954336560086]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Execute training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[32m      5\u001b[39m val_metrics = trainer.evaluate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:4071\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   4068\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   4069\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4071\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\accelerate\\accelerator.py:2852\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2850\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2851\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2852\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Execute training\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_metrics = trainer.evaluate()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "for key, value in val_metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save the best model\n",
    "model_save_path = \"./models/roberta-environmental-sentiment-best\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"\\n✓ Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c87319",
   "metadata": {},
   "source": [
    "## Phase 5: Model Evaluation on Test Set\n",
    "\n",
    "Generate predictions and detailed performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "predictions = trainer.predict(test_tokenized)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "pred_probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "# Get true labels\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Compute test metrics\n",
    "test_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "test_f1_macro = f1_score(true_labels, pred_labels, average=\"macro\")\n",
    "test_f1_weighted = f1_score(true_labels, pred_labels, average=\"weighted\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"TEST SET METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"F1 Macro: {test_f1_macro:.4f}\")\n",
    "print(f\"F1 Weighted: {test_f1_weighted:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(\n",
    "    true_labels, \n",
    "    pred_labels, \n",
    "    target_names=[\"Negative\", \"Neutral\", \"Positive\"],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*50)\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(\"           Predicted\")\n",
    "print(\"           Neg  Neu  Pos\")\n",
    "for i, label in enumerate([\"Negative\", \"Neutral\", \"Positive\"]):\n",
    "    print(f\"Actual {label:8s} {cm[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e883c",
   "metadata": {},
   "source": [
    "## Phase 6: Prepare Predictions DataFrame\n",
    "\n",
    "Create enriched dataset with predictions, probabilities, and metadata for temporal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results dataframe\n",
    "results_df = test_df.copy()\n",
    "results_df['predicted_label'] = pred_labels\n",
    "results_df['predicted_sentiment'] = results_df['predicted_label'].map(id2label)\n",
    "results_df['prob_negative'] = pred_probs[:, 0]\n",
    "results_df['prob_neutral'] = pred_probs[:, 1]\n",
    "results_df['prob_positive'] = pred_probs[:, 2]\n",
    "results_df['confidence'] = pred_probs.max(axis=1)\n",
    "\n",
    "# Calculate sentiment score (-1 to +1 scale)\n",
    "results_df['sentiment_score'] = (\n",
    "    results_df['prob_positive'] - results_df['prob_negative']\n",
    ")\n",
    "\n",
    "# Ensure timestamp is datetime\n",
    "results_df['timestamp'] = pd.to_datetime(results_df['timestamp'])\n",
    "\n",
    "print(f\"Results DataFrame shape: {results_df.shape}\")\n",
    "print(f\"\\nSample predictions:\")\n",
    "print(results_df[['text', 'sentiment_label', 'predicted_sentiment', 'sentiment_score', 'confidence']].head(10))\n",
    "\n",
    "# Save predictions for future analysis\n",
    "results_df.to_csv(\"predictions_with_metadata.csv\", index=False)\n",
    "print(\"\\n✓ Predictions saved to: predictions_with_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0af82",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 7: Temporal Aggregation & Trend Analysis\n",
    "\n",
    "Aggregate sentiment scores by time windows and platform to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbfb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal aggregation functions\n",
    "def aggregate_by_time(df, freq='W', score_col='sentiment_score'):\n",
    "    \"\"\"\n",
    "    Aggregate sentiment by time period\n",
    "    freq: 'D' (daily), 'W' (weekly), 'M' (monthly)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.set_index('timestamp')\n",
    "    \n",
    "    aggregated = df.groupby(pd.Grouper(freq=freq)).agg({\n",
    "        score_col: ['mean', 'std', 'count'],\n",
    "        'prob_positive': 'mean',\n",
    "        'prob_neutral': 'mean',\n",
    "        'prob_negative': 'mean',\n",
    "        'confidence': 'mean'\n",
    "    })\n",
    "    \n",
    "    aggregated.columns = ['_'.join(col).strip() for col in aggregated.columns.values]\n",
    "    aggregated = aggregated.reset_index()\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "# Weekly aggregation\n",
    "weekly_sentiment = aggregate_by_time(results_df, freq='W')\n",
    "print(\"Weekly Sentiment Aggregation:\")\n",
    "print(weekly_sentiment.head(10))\n",
    "print(f\"\\nTotal weeks: {len(weekly_sentiment)}\")\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_sentiment = aggregate_by_time(results_df, freq='M')\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Monthly Sentiment Aggregation:\")\n",
    "print(monthly_sentiment.head())\n",
    "\n",
    "# Aggregate by platform\n",
    "platform_sentiment = results_df.groupby('platform').agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count'],\n",
    "    'prob_positive': 'mean',\n",
    "    'prob_neutral': 'mean',\n",
    "    'prob_negative': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "platform_sentiment.columns = ['_'.join(col).strip() if col[1] else col[0] \n",
    "                               for col in platform_sentiment.columns.values]\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Platform-wise Sentiment:\")\n",
    "print(platform_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebdb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Platform aggregation for cross-analysis\n",
    "weekly_platform = results_df.set_index('timestamp').groupby([\n",
    "    pd.Grouper(freq='W'),\n",
    "    'platform'\n",
    "]).agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'text': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "weekly_platform.columns = ['timestamp', 'platform', 'avg_sentiment', 'post_count']\n",
    "\n",
    "print(\"Weekly Sentiment by Platform:\")\n",
    "print(weekly_platform.head(15))\n",
    "\n",
    "# Calculate rolling averages (4-week moving average)\n",
    "results_df_sorted = results_df.sort_values('timestamp')\n",
    "results_df_sorted = results_df_sorted.set_index('timestamp')\n",
    "\n",
    "rolling_sentiment = results_df_sorted['sentiment_score'].resample('D').mean().rolling(\n",
    "    window=28, min_periods=7\n",
    ").mean().reset_index()\n",
    "\n",
    "rolling_sentiment.columns = ['timestamp', 'rolling_avg_28d']\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"28-Day Rolling Average Sentiment:\")\n",
    "print(rolling_sentiment.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1090b8fd",
   "metadata": {},
   "source": [
    "## Phase 8: Time-Series Visualization\n",
    "\n",
    "Create comprehensive time-series charts showing sentiment evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overall sentiment trends over time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# 1. Weekly Sentiment Time Series with all sentiment types\n",
    "fig1 = go.Figure()\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=weekly_sentiment['timestamp'],\n",
    "    y=weekly_sentiment['prob_positive_mean'],\n",
    "    mode='lines+markers',\n",
    "    name='Positive',\n",
    "    line=dict(color='green', width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=weekly_sentiment['timestamp'],\n",
    "    y=weekly_sentiment['prob_neutral_mean'],\n",
    "    mode='lines+markers',\n",
    "    name='Neutral',\n",
    "    line=dict(color='gray', width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=weekly_sentiment['timestamp'],\n",
    "    y=weekly_sentiment['prob_negative_mean'],\n",
    "    mode='lines+markers',\n",
    "    name='Negative',\n",
    "    line=dict(color='red', width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "fig1.update_layout(\n",
    "    title='Weekly Sentiment Distribution Over Time',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Average Probability',\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "# 2. Sentiment Score Time Series (Composite -1 to +1)\n",
    "fig2 = go.Figure()\n",
    "\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=weekly_sentiment['timestamp'],\n",
    "    y=weekly_sentiment['sentiment_score_mean'],\n",
    "    mode='lines+markers',\n",
    "    name='Sentiment Score',\n",
    "    line=dict(color='blue', width=3),\n",
    "    marker=dict(size=8),\n",
    "    fill='tozeroy',\n",
    "    fillcolor='rgba(0,100,255,0.2)'\n",
    "))\n",
    "\n",
    "# Add zero line for reference\n",
    "fig2.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", opacity=0.5)\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='Weekly Sentiment Score Trend (-1: Negative, +1: Positive)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Average Sentiment Score',\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Platform Comparison Time Series\n",
    "fig3 = px.line(\n",
    "    weekly_platform,\n",
    "    x='timestamp',\n",
    "    y='avg_sentiment',\n",
    "    color='platform',\n",
    "    markers=True,\n",
    "    title='Sentiment Trends by Platform',\n",
    "    labels={'avg_sentiment': 'Average Sentiment Score', 'timestamp': 'Date'}\n",
    ")\n",
    "\n",
    "fig3.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", opacity=0.3)\n",
    "\n",
    "fig3.update_layout(\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig3.show()\n",
    "\n",
    "# 4. Volume and Sentiment Combined View\n",
    "fig4 = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=('Sentiment Score Over Time', 'Post Volume Over Time'),\n",
    "    vertical_spacing=0.12,\n",
    "    specs=[[{\"secondary_y\": False}], [{\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Sentiment trend\n",
    "fig4.add_trace(\n",
    "    go.Scatter(\n",
    "        x=weekly_sentiment['timestamp'],\n",
    "        y=weekly_sentiment['sentiment_score_mean'],\n",
    "        mode='lines+markers',\n",
    "        name='Sentiment Score',\n",
    "        line=dict(color='blue', width=2)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Volume trend\n",
    "fig4.add_trace(\n",
    "    go.Bar(\n",
    "        x=weekly_sentiment['timestamp'],\n",
    "        y=weekly_sentiment['sentiment_score_count'],\n",
    "        name='Post Count',\n",
    "        marker_color='lightblue'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig4.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig4.update_yaxes(title_text=\"Sentiment Score\", row=1, col=1)\n",
    "fig4.update_yaxes(title_text=\"Number of Posts\", row=2, col=1)\n",
    "\n",
    "fig4.update_layout(\n",
    "    title_text='Sentiment & Volume Analysis',\n",
    "    showlegend=True,\n",
    "    template='plotly_white',\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8007789",
   "metadata": {},
   "source": [
    "## Phase 9: Geographic Heatmap\n",
    "\n",
    "Visualize sentiment intensity by geolocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81996488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment by geolocation\n",
    "geo_sentiment = results_df.groupby('geolocation').agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count'],\n",
    "    'prob_positive': 'mean',\n",
    "    'prob_negative': 'mean',\n",
    "    'prob_neutral': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "geo_sentiment.columns = ['geolocation', 'avg_sentiment', 'std_sentiment', \n",
    "                         'post_count', 'avg_positive', 'avg_negative', 'avg_neutral']\n",
    "\n",
    "# Sort by average sentiment\n",
    "geo_sentiment_sorted = geo_sentiment.sort_values('avg_sentiment', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Positive Regions:\")\n",
    "print(geo_sentiment_sorted.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Top 10 Most Negative Regions:\")\n",
    "print(geo_sentiment_sorted.tail(10))\n",
    "\n",
    "# Geographic Heatmap (Bar Chart representation)\n",
    "fig5 = px.bar(\n",
    "    geo_sentiment_sorted.head(20),\n",
    "    x='geolocation',\n",
    "    y='avg_sentiment',\n",
    "    color='avg_sentiment',\n",
    "    color_continuous_scale=['red', 'yellow', 'green'],\n",
    "    color_continuous_midpoint=0,\n",
    "    title='Top 20 Locations by Average Sentiment Score',\n",
    "    labels={'avg_sentiment': 'Average Sentiment', 'geolocation': 'Location'},\n",
    "    hover_data=['post_count', 'avg_positive', 'avg_negative']\n",
    ")\n",
    "\n",
    "fig5.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig5.show()\n",
    "\n",
    "# Alternative: Heatmap Matrix by Location and Time Period\n",
    "# Prepare data for time-location heatmap\n",
    "results_df['month'] = results_df['timestamp'].dt.to_period('M').astype(str)\n",
    "\n",
    "geo_time_matrix = results_df.groupby(['geolocation', 'month'])['sentiment_score'].mean().reset_index()\n",
    "geo_time_pivot = geo_time_matrix.pivot(index='geolocation', columns='month', values='sentiment_score')\n",
    "\n",
    "# Filter to top locations by volume\n",
    "top_locations = results_df['geolocation'].value_counts().head(15).index\n",
    "geo_time_filtered = geo_time_pivot.loc[geo_time_pivot.index.isin(top_locations)]\n",
    "\n",
    "fig6 = px.imshow(\n",
    "    geo_time_filtered,\n",
    "    color_continuous_scale='RdYlGn',\n",
    "    color_continuous_midpoint=0,\n",
    "    title='Sentiment Heatmap: Top Locations Over Time',\n",
    "    labels=dict(x=\"Month\", y=\"Location\", color=\"Sentiment Score\"),\n",
    "    aspect='auto'\n",
    ")\n",
    "\n",
    "fig6.update_layout(\n",
    "    height=600,\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dddb11",
   "metadata": {},
   "source": [
    "## Phase 10: Advanced Analytics & Insights\n",
    "\n",
    "Statistical analysis and key findings from sentiment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baedcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecast with Plotly\n",
    "fig7 = go.Figure()\n",
    "\n",
    "# Historical data\n",
    "fig7.add_trace(go.Scatter(\n",
    "    x=daily_sentiment['ds'],\n",
    "    y=daily_sentiment['y'],\n",
    "    mode='markers',\n",
    "    name='Historical Data',\n",
    "    marker=dict(size=4, color='blue', opacity=0.6)\n",
    "))\n",
    "\n",
    "# Forecast\n",
    "fig7.add_trace(go.Scatter(\n",
    "    x=forecast['ds'],\n",
    "    y=forecast['yhat'],\n",
    "    mode='lines',\n",
    "    name='Forecast',\n",
    "    line=dict(color='red', width=2)\n",
    "))\n",
    "\n",
    "# Confidence interval\n",
    "fig7.add_trace(go.Scatter(\n",
    "    x=forecast['ds'],\n",
    "    y=forecast['yhat_upper'],\n",
    "    mode='lines',\n",
    "    name='Upper Bound',\n",
    "    line=dict(width=0),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig7.add_trace(go.Scatter(\n",
    "    x=forecast['ds'],\n",
    "    y=forecast['yhat_lower'],\n",
    "    mode='lines',\n",
    "    name='Confidence Interval',\n",
    "    line=dict(width=0),\n",
    "    fillcolor='rgba(255, 0, 0, 0.1)',\n",
    "    fill='tonexty'\n",
    "))\n",
    "\n",
    "fig7.update_layout(\n",
    "    title='90-Day Sentiment Forecast: Environmental Policy Perception',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Sentiment Score',\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig7.show()\n",
    "\n",
    "# Display forecast statistics\n",
    "future_only = forecast[forecast['ds'] > daily_sentiment['ds'].max()]\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FORECAST SUMMARY (Next 90 Days)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Average Predicted Sentiment: {future_only['yhat'].mean():.4f}\")\n",
    "print(f\"Trend Direction: {'Positive' if future_only['yhat'].iloc[-1] > future_only['yhat'].iloc[0] else 'Negative'}\")\n",
    "print(f\"Predicted Range: {future_only['yhat'].min():.4f} to {future_only['yhat'].max():.4f}\")\n",
    "print(f\"\\nLast Historical Sentiment: {daily_sentiment['y'].iloc[-1]:.4f}\")\n",
    "print(f\"First Forecast (tomorrow): {future_only['yhat'].iloc[0]:.4f}\")\n",
    "print(f\"Final Forecast (90 days): {future_only['yhat'].iloc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfee615",
   "metadata": {},
   "source": [
    "## Phase 11: Advanced Analytics & Insights\n",
    "\n",
    "Statistical analysis and key findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941dd666",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: MLOps Pipeline Complete ✓\n",
    "\n",
    "**Completed Tasks:**\n",
    "\n",
    "1. ✓ **Fine-Tuning**: RoBERTa-base fine-tuned on sentiment data with robust evaluation (F1, Accuracy)\n",
    "2. ✓ **Model Evaluation**: Comprehensive metrics including confusion matrix and per-class F1 scores\n",
    "3. ✓ **Prediction Pipeline**: Generated sentiment scores with confidence metrics for entire test set\n",
    "4. ✓ **Temporal Aggregation**: Weekly/Monthly rolling averages grouped by time and platform\n",
    "5. ✓ **Visualization**: Interactive Plotly charts showing sentiment evolution, platform comparison, and volume trends\n",
    "6. ✓ **Geographic Analysis**: Heatmap showing sentiment intensity by location\n",
    "7. ✓ **Statistical Analysis**: Comprehensive trend analysis, volatility metrics, and insights\n",
    "\n",
    "**Output Files:**\n",
    "- `models/roberta-environmental-sentiment-best/` - Fine-tuned model checkpoint\n",
    "- `predictions_with_metadata.csv` - Full predictions with timestamps, platforms, geolocation\n",
    "\n",
    "**Key Insights Available:**\n",
    "- Temporal trends and seasonality patterns\n",
    "- Platform-specific sentiment differences\n",
    "- Geographic sentiment distribution\n",
    "- Statistical summary and volatility analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q transformers datasets torch scikit-learn pandas plotly prophet kaleido"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
