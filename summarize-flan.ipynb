{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1409370",
   "metadata": {},
   "source": [
    "# FLAN-T5 Opinion Summarization\n",
    "---\n",
    "\n",
    "Summarizing multiple opinions/comments using FLAN-T5-large model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78d6e0",
   "metadata": {},
   "source": [
    "**Loading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a253fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load FLAN-T5-large model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.float32  # CPU usage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79672d07",
   "metadata": {},
   "source": [
    "**Defining the Summarization Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057d84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization function\n",
    "def summarize_opinions(comments, topic=None, max_input_tokens=400, max_length=128, min_length=20, temperature=0.3, num_beams=4):\n",
    "    \"\"\"\n",
    "    Summarize a list of comments and provide a general analysis.\n",
    "    Handles long text by chunking if necessary.\n",
    "    \n",
    "    Args:\n",
    "        comments (list): List of comment strings\n",
    "        topic (str, optional): The topic being discussed\n",
    "        max_input_tokens (int): Maximum tokens for input text (default 400, leaving room for prompt)\n",
    "        max_length (int): Maximum tokens in generated summary (default 128)\n",
    "        min_length (int): Minimum tokens in generated summary (default 20)\n",
    "        temperature (float): Controls randomness (0.1-1.0, default 0.3)\n",
    "        num_beams (int): Number of beams for beam search (default 4)\n",
    "    \n",
    "    Returns:\n",
    "        str: General summary of public opinion\n",
    "    \"\"\"\n",
    "    \n",
    "    def create_prompt(text, topic):\n",
    "        \"\"\"Create the prompt for summarization\"\"\"\n",
    "        if topic:\n",
    "            return (\n",
    "                f\"Review these comments about {topic}:\\n\"\n",
    "                f\"{text}\\n\\n\"\n",
    "                f\"Instruction: Analyze the comments and provide a general summary of the public opinion on {topic}.\"\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                f\"Analyze these comments:\\n\"\n",
    "                f\"{text}\\n\\n\"\n",
    "                f\"Instruction: Analyze the comments and provide a general summary of the overall sentiment and key themes.\"\n",
    "            )\n",
    "    \n",
    "    def summarize_chunk(text_chunk, topic):\n",
    "        \"\"\"Summarize a single chunk of text\"\"\"\n",
    "        prompt = create_prompt(text_chunk, topic)\n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        summary_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            min_length=min_length,\n",
    "            temperature=temperature,\n",
    "            num_beams=num_beams,\n",
    "            do_sample=True,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    combined_text = \"\\n\".join([f\"- {c}\" for c in comments])\n",
    "    test_prompt = create_prompt(combined_text, topic)\n",
    "    tokens = tokenizer.encode(test_prompt)\n",
    "    \n",
    "    # If it fits, process normally\n",
    "    if len(tokens) <= 512:\n",
    "        return summarize_chunk(combined_text, topic)\n",
    "    print(f\"Input too long ({len(tokens)} tokens). Processing in chunks...\")\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for comment in comments:\n",
    "        comment_text = f\"- {comment}\\n\"\n",
    "        comment_tokens = len(tokenizer.encode(comment_text))\n",
    "        \n",
    "        # If adding this comment exceeds the limit, save current chunk and start new one\n",
    "        if current_length + comment_tokens > max_input_tokens and current_chunk:\n",
    "            chunks.append(\"\\n\".join(current_chunk))\n",
    "            current_chunk = [comment_text.strip()]\n",
    "            current_length = comment_tokens\n",
    "        else:\n",
    "            current_chunk.append(comment_text.strip())\n",
    "            current_length += comment_tokens\n",
    "    \n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\\n\".join(current_chunk))\n",
    "    \n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "        summary = summarize_chunk(chunk, topic)\n",
    "        chunk_summaries.append(summary)\n",
    "    \n",
    "    # If only one chunk, return it\n",
    "    if len(chunk_summaries) == 1:\n",
    "        return chunk_summaries[0]\n",
    "    \n",
    "    # Otherwise, combine the chunk summaries into a final summary\n",
    "    print(\"Combining chunk summaries...\")\n",
    "    combined_summaries = \"\\n\".join([f\"- {s}\" for s in chunk_summaries])\n",
    "    final_prompt = (\n",
    "        f\"Combine these summaries about {topic if topic else 'the topic'}:\\n\"\n",
    "        f\"{combined_summaries}\\n\\n\"\n",
    "        f\"Instruction: Analyze these summaries and provide a comprehensive general summary of the overall opinion.\"\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        final_prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        temperature=temperature,\n",
    "        num_beams=num_beams,\n",
    "        do_sample=True,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbe490",
   "metadata": {},
   "source": [
    "\n",
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d24349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONFIGURATION =====\n",
    "\n",
    "max_length = 130 # token length\n",
    "min_length = 20\n",
    "temperature = 0.30 # creativity level\n",
    "num_beams = 4 # beams for beam search (affects quality and speed)\n",
    "\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a116de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments to summarize: 25\n",
      "\n",
      "============================================================\n",
      "RAW COMMENTS:\n",
      "============================================================\n",
      "Renewable energy requires change through activism. Global warming should be embraced through education. Climate mitigation prevents catastrophic warming scenarios.\n",
      "Environmental protection is everyone's responsibility at every level. Reforestation is urgent through activism. Water conservation reduces pollution starting today.\n",
      "Water conservation can save our planet starting today. Green innovation drives economic growth while protecting environment. Climate activism promotes cleaner air to empower communities.\n",
      "Green infrastructure projects provide multiple environmental benefits. Sustainable transportation reduces urban pollution significantly. Circular economy builds a greener future by reducing waste.\n",
      "LED lighting saves energy consumption dramatically. Renewable energy is everyone's responsibility by reducing waste. Green buildings improve energy efficiency markedly.\n",
      "Green technology is essential through innovation. Climate justice should be embraced with collective effort. Eco-friendly habits fights climate crisis with sustainable policies.\n",
      "Nature conservation promotes cleaner air to protect ecosystems. Circular economy is everyone's responsibility by reducing waste. Climate hope inspires continued action persistence.\n",
      "Earth preservation reduces pollution in cities and rural areas. Environmental protection can save our planet at every level. Sustainable materials science develops eco-friendly alternatives.\n",
      "Carbon footprint promotes cleaner air to secure our future. Green finance instruments fund environmental protection projects. Earth preservation is the future in cities and rural areas.\n",
      "Reforestation builds a greener future through activism. Climate litigation enforces environmental protection legally. Wind farms generate clean electricity sustainably.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "SUMMARY:\n",
      "Green technology is essential through innovation. Climate justice should be embraced with collective effort. Eco-friendly habits fights climate crisis with sustainable policies.\n",
      "\n",
      "SUMMARY:\n",
      "Green technology is essential through innovation. Climate justice should be embraced with collective effort. Eco-friendly habits fights climate crisis with sustainable policies.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sustainability_social_media_posts.csv\")\n",
    "\n",
    "# head (mixed)\n",
    "# sample_comments = df[\"post_text\"].head(10).tolist()\n",
    "\n",
    "# filtered (same sentiment and topic)\n",
    "sample_comments = df[(df[\"post_sentiment\"] == \"Positive\") & \n",
    "                       (df[\"climate_topic\"] == \"Climate Policy\")][\"post_text\"].tolist()\n",
    "\n",
    "print(f\"Total comments to summarize: {len(sample_comments)}\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RAW COMMENTS:\")\n",
    "print(\"=\"*60)\n",
    "for comment in sample_comments[:10]:\n",
    "    print(f\"{comment}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "result = summarize_opinions(\n",
    "    sample_comments[:10],\n",
    "    topic=None,\n",
    "    max_length=max_length,\n",
    "    min_length=min_length,\n",
    "    temperature=temperature,\n",
    "    num_beams=num_beams\n",
    ")\n",
    "print(f\"\\nSUMMARY:\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52aa989",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a2ba9",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
