{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Streamlined Sentiment Analysis & Summary\n",
    "This notebook focuses on sentiment analysis and summary generation using a pre-trained RoBERTa model.\n",
    "No training required - uses cardiffnlp/twitter-roberta-base-sentiment-latest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "i9j0k1l2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "m3n4o5p6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully!\n",
      "Device: CPU\n",
      "Label mappings: {0: 'negative', 1: 'neutral', 2: 'positive'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize pre-trained RoBERTa sentiment model\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "print(f\"Loading pre-trained model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create sentiment pipeline\n",
    "sentiment_pipeline = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Display label mappings\n",
    "labels = model.config.id2label\n",
    "print(f\"\\nModel loaded successfully!\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Label mappings: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 records from 1k_sample.csv\n",
      "\n",
      "Dataset shape: (890, 3)\n",
      "\n",
      "Columns: ['sentiment', 'message', 'tweetid']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>@tiniebeany climate change is an interesting h...</td>\n",
       "      <td>792927353886371840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right...</td>\n",
       "      <td>793124211518832641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fabulous! Leonardo #DiCaprio's film on #climat...</td>\n",
       "      <td>793124402388832256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Mick_Fanning: Just watched this amazing do...</td>\n",
       "      <td>793124635873275904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @cnalive: Pranita Biswasi, a Lutheran from ...</td>\n",
       "      <td>793125156185137153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0         -1  @tiniebeany climate change is an interesting h...   \n",
       "1          1  RT @NatGeoChannel: Watch #BeforeTheFlood right...   \n",
       "2          1  Fabulous! Leonardo #DiCaprio's film on #climat...   \n",
       "3          1  RT @Mick_Fanning: Just watched this amazing do...   \n",
       "4          2  RT @cnalive: Pranita Biswasi, a Lutheran from ...   \n",
       "\n",
       "              tweetid  \n",
       "0  792927353886371840  \n",
       "1  793124211518832641  \n",
       "2  793124402388832256  \n",
       "3  793124635873275904  \n",
       "4  793125156185137153  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your data from CSV\n",
    "# Adjust the path and column names as needed\n",
    "csv_path = \"1k_sample.csv\"  # Change to your file: twitter_sentiment_data.csv, 5k_sample.csv, etc.\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df)} records from {csv_path}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "# Automatically detect the text column\n",
    "text_column = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in ['text', 'tweet', 'comment', 'message', 'content', 'review']:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    # Use the first column that appears to contain text\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            text_column = col\n",
    "            break\n",
    "\n",
    "print(f\"\\nUsing column '{text_column}' for sentiment analysis\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y5z6a7b8",
   "metadata": {},
   "source": [
    "## 3. Perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test on a few samples first\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sample_texts = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_column\u001b[49m\u001b[43m]\u001b[49m.head(\u001b[32m5\u001b[39m).tolist()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting on sample texts:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_texts, \u001b[32m1\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\codes\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'text'"
     ]
    }
   ],
   "source": [
    "# Test on a few samples first\n",
    "sample_texts = df[text_column].head(5).tolist()\n",
    "print(\"Testing on sample texts:\\n\")\n",
    "\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    result = sentiment_pipeline(text, top_k=1)\n",
    "    print(f\"{i}. Text: {text[:80]}...\")\n",
    "    print(f\"   Sentiment: {result[0]['label']} (confidence: {result[0]['score']:.3f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g3h4i5j6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all texts in batches for efficiency\n",
    "print(\"Analyzing all texts...\")\n",
    "\n",
    "batch_size = 32\n",
    "all_texts = df[text_column].fillna(\"\").tolist()\n",
    "all_results = []\n",
    "\n",
    "for i in range(0, len(all_texts), batch_size):\n",
    "    batch = all_texts[i:i+batch_size]\n",
    "    results = sentiment_pipeline(batch, top_k=1, truncation=True, max_length=512)\n",
    "    all_results.extend(results)\n",
    "    if (i // batch_size + 1) % 10 == 0:\n",
    "        print(f\"Processed {i+len(batch)}/{len(all_texts)} texts...\")\n",
    "\n",
    "print(f\"\\nAnalysis complete! Processed {len(all_results)} texts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataframe\n",
    "df['predicted_sentiment'] = [result[0]['label'] for result in all_results]\n",
    "df['confidence_score'] = [result[0]['score'] for result in all_results]\n",
    "\n",
    "print(\"Predictions added to dataframe!\")\n",
    "print(f\"\\nSample results:\")\n",
    "df[[text_column, 'predicted_sentiment', 'confidence_score']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1p2q3r4",
   "metadata": {},
   "source": [
    "## 4. Generate Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5t6u7v8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall sentiment distribution\n",
    "sentiment_counts = df['predicted_sentiment'].value_counts()\n",
    "sentiment_percentages = df['predicted_sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SENTIMENT ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal texts analyzed: {len(df)}\")\n",
    "print(f\"\\n{'Sentiment':<15} {'Count':<10} {'Percentage':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for sentiment in sentiment_counts.index:\n",
    "    count = sentiment_counts[sentiment]\n",
    "    pct = sentiment_percentages[sentiment]\n",
    "    print(f\"{sentiment:<15} {count:<10} {pct:>6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w9x0y1z2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence statistics\n",
    "print(\"\\nCONFIDENCE SCORE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean confidence: {df['confidence_score'].mean():.4f}\")\n",
    "print(f\"Median confidence: {df['confidence_score'].median():.4f}\")\n",
    "print(f\"Min confidence: {df['confidence_score'].min():.4f}\")\n",
    "print(f\"Max confidence: {df['confidence_score'].max():.4f}\")\n",
    "print(f\"Std deviation: {df['confidence_score'].std():.4f}\")\n",
    "\n",
    "# Confidence by sentiment\n",
    "print(\"\\nAverage confidence by sentiment:\")\n",
    "for sentiment in df['predicted_sentiment'].unique():\n",
    "    avg_conf = df[df['predicted_sentiment'] == sentiment]['confidence_score'].mean()\n",
    "    print(f\"  {sentiment}: {avg_conf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8g9h0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Sentiment distribution (bar chart)\n",
    "sentiment_counts.plot(kind='bar', ax=axes[0], color=['#d62728', '#7f7f7f', '#2ca02c'])\n",
    "axes[0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentiment', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, v in enumerate(sentiment_counts):\n",
    "    axes[0].text(i, v + 0.5, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Sentiment distribution (pie chart)\n",
    "colors = ['#d62728', '#7f7f7f', '#2ca02c']\n",
    "sentiment_order = ['negative', 'neutral', 'positive']\n",
    "plot_data = [sentiment_counts.get(s, 0) for s in sentiment_order]\n",
    "axes[1].pie(plot_data, labels=sentiment_order, autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors, textprops={'fontsize': 11})\n",
    "axes[1].set_title('Sentiment Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i1j2k3l4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confidence score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Overall confidence distribution\n",
    "axes[0].hist(df['confidence_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Confidence Score', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].axvline(df['confidence_score'].mean(), color='red', linestyle='--', \n",
    "                linewidth=2, label=f\"Mean: {df['confidence_score'].mean():.3f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Confidence by sentiment (box plot)\n",
    "df.boxplot(column='confidence_score', by='predicted_sentiment', ax=axes[1])\n",
    "axes[1].set_title('Confidence Score by Sentiment', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Sentiment', fontsize=12)\n",
    "axes[1].set_ylabel('Confidence Score', fontsize=12)\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m5n6o7p8",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q9r0s1t2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show most confident predictions for each sentiment\n",
    "print(\"MOST CONFIDENT PREDICTIONS BY SENTIMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for sentiment in ['positive', 'neutral', 'negative']:\n",
    "    print(f\"\\n{sentiment.upper()}:\")\n",
    "    print(\"-\" * 80)\n",
    "    subset = df[df['predicted_sentiment'] == sentiment].nlargest(3, 'confidence_score')\n",
    "    for idx, (_, row) in enumerate(subset.iterrows(), 1):\n",
    "        text = row[text_column][:100] + \"...\" if len(row[text_column]) > 100 else row[text_column]\n",
    "        print(f\"{idx}. {text}\")\n",
    "        print(f\"   Confidence: {row['confidence_score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u3v4w5x6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show least confident predictions (potential edge cases)\n",
    "print(\"\\nLEAST CONFIDENT PREDICTIONS (Potential Edge Cases)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "least_confident = df.nsmallest(5, 'confidence_score')\n",
    "for idx, (_, row) in enumerate(least_confident.iterrows(), 1):\n",
    "    text = row[text_column][:100] + \"...\" if len(row[text_column]) > 100 else row[text_column]\n",
    "    print(f\"{idx}. Text: {text}\")\n",
    "    print(f\"   Predicted: {row['predicted_sentiment']} (confidence: {row['confidence_score']:.4f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y7z8a9b0",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "output_file = \"sentiment_analysis_results.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Create summary report\n",
    "summary_file = \"sentiment_summary.txt\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"SENTIMENT ANALYSIS SUMMARY REPORT\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Model: {MODEL_NAME}\\n\")\n",
    "    f.write(f\"Total texts analyzed: {len(df)}\\n\\n\")\n",
    "    f.write(\"Sentiment Distribution:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    for sentiment in sentiment_counts.index:\n",
    "        count = sentiment_counts[sentiment]\n",
    "        pct = sentiment_percentages[sentiment]\n",
    "        f.write(f\"  {sentiment}: {count} ({pct:.2f}%)\\n\")\n",
    "    f.write(\"\\nConfidence Statistics:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"  Mean: {df['confidence_score'].mean():.4f}\\n\")\n",
    "    f.write(f\"  Median: {df['confidence_score'].median():.4f}\\n\")\n",
    "    f.write(f\"  Std Dev: {df['confidence_score'].std():.4f}\\n\")\n",
    "\n",
    "print(f\"Summary report saved to {summary_file}\")\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
